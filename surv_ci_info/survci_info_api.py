# -*- coding: utf-8 -*-
"""csa_api.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OfXVnydZA5UonDed1gTcBbFmpMLW4YTY
"""


from surv_ci_info.train_utils import train_survci_info
from surv_ci_info.train_utils import _get_padded_features, _get_padded_targets
from surv_ci_info.train_utils import _reshape_tensor_with_nans
from surv_ci_info.utilities import get_parameters, softmax_out, sample_weibull, sample_lognormal,auc
from surv_ci_info.model import survci_info
from lifelines.utils import concordance_index
from surv_ci_info.losses import conditional_loss,unconditional_loss,mse_loss,imb_loss,l2_loss
import pdb
import torch
import numpy as np

np.random.seed(1234)
torch.manual_seed(seed=1234)

if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")
  
class survci_infoBase():

  def __init__(self, name,k=3, layers=None, distribution="Weibull",
               temp=1000., discount=1.0,imb_func='lin_disc',p_ipm=0.5,p_alpha=1e-2,p_beta =1e-4,p_gamma=1e-1,p_lamda=1e-2):
    self.k = k
    self.layers = layers
    self.dist = distribution
    self.temp = temp
    self.discount = discount
    self.fitted = False
    self.imb_func = imb_func
    self.p_ipm = p_ipm
    self.p_alpha = p_alpha
    self.p_beta = p_beta
    self.p_gamma = p_gamma #change
    self.p_lamda = p_lamda #change
    self.name = name

  def _gen_torch_model(self, inputdim, optimizer, num_treatments):
    """Helper function to return a torch model."""
    return survci_info(inputdim,k=self.k,layers=self.layers,
                                     dist=self.dist,
                                     temp=self.temp,
                                     discount=self.discount,
                                     optimizer=optimizer,
                                     num_treatments=2,imb_func=self.imb_func,p_ipm=self.p_ipm,p_alpha=self.p_alpha, p_beta = self.p_beta,p_gamma=self.p_gamma,p_lamda=self.p_lamda)
  

  #def fit(self, x, t,c, e,w, vsize=0.15, val_data=None,
          # iters=1, learning_rate=1e-3, batch_size=100,
          # elbo=True, optimizer="Adam", random_state=1234):

  def fit(self,x,y,e,w,vsize=0.5,val_data=None,
           iters=1,learning_rate=1e-3,batch_size=100,
           elbo=True,optimizer='Adam',random_state=1234):

    #processed_data = self._prepocess_training_data(x, t, c,e,w,
                                                   #vsize, val_data,
                                                   #random_state)
    #x_train, t_train, c_train, e_train,w_train, x_val, t_val, c_val,e_val,w_val = processed_data
    processed_data = self._prepocess_training_data(x, y,e,w,
                                                   vsize, val_data,
                                                   random_state)
    x_train ,y_train, e_train,w_train, x_val, y_val,e_val,w_val = processed_data

    inputdim = x_train.shape[-1]

   
    model = self._gen_torch_model(inputdim, optimizer, num_treatments=2)
    # model, _ = train_survci_info(model,
    #                      x_train, t_train,c_train, e_train,w_train,
    #                      x_val, t_val, c_val, e_val,w_val,
    #                      n_iter=iters,
    #                      lr=learning_rate,
    #                      elbo=elbo,
    #                      bs=batch_size)
    # pdb.set_trace()
    model,_ = train_survci_info(model,
                         x_train,y_train, e_train,w_train,
                         x_val, y_val, e_val,w_val,name=self.name,
                         n_iter=iters,
                         lr=learning_rate,
                         elbo=elbo,
                         bs=batch_size)
    #pdb.set_trace()
    self.torch_model = model.eval()
    self.fitted = True

    return self    

  #def compute_loss(self, x, t, c,e,w):
  def compute_loss(self, x , y, e,w):

    if not self.fitted:
      raise Exception("The model has not been fitted yet. Please fit the " +
                      "model using the `fit` method on some training data " +
                      "before calling `_eval_nll`.")
    processed_data = self._prepocess_training_data(x, y,e,w, 0, None, 0)
    _, _,_, _,_, x_val, y_val, e_val,w_val = processed_data

    x_val, y_val,e_val,w_val = x_val,\
        _reshape_tensor_with_nans(y_val),\
        _reshape_tensor_with_nans(e_val),\
        _reshape_tensor_with_nans(w_val)
    loss = 0
    ll_loss = float(conditional_loss(self.torch_model,x_val, y_val, e_val,w_val, elbo=False))
    imb = imb_loss(self.torch_model,x_val,w_val)
    mse = mse_loss(self.torch_model,x_val,y_val,e_val,w_val)
    l_f = factual_loss(self.torch_model,x_val,y_val,e_val,w_val)
    l2 = l2_loss(self.torch_model) #change

    processed_data = self._prepocess_training_data(x, y,e,w, 0, None, 0)
    _, _,_, _,_, x_val, t_val,c_val, e_val,w_val = processed_data

    # x_val, t_val, c_val,e_val,w_val = x_val,\
    #     _reshape_tensor_with_nans(t_val),\
    #     _reshape_tensor_with_nans(c_val),\
    #     _reshape_tensor_with_nans(e_val),\
    #     _reshape_tensor_with_nans(w_val)
    # loss = 0
    # ll_loss = float(conditional_loss(self.torch_model,x_val, t_val,c_val, e_val,w_val, elbo=False))
    # imb = imb_loss(self.torch_model,x_val,w_val)
    # mse = mse_loss(self.torch_model,x_val,t_val,c_val,w_val)
    # l_f = factual_loss(self.torch_model,x_val,t_val,c_val,e_val,w_val)
    ## mse = mse_total(self.torch_model,x_val,t_val,e_val,w_val)
    loss = self.torch_model.p_gamma*ll_loss + self.torch_model.p_alpha*imb + self.torch_model.p_beta*mse +self.torch_model.p_lamda*l2_loss
    
    ##loss = ll_loss+self.torch_model.p_alpha*imb + self.torch_model.p_beta*l_f
    
    return loss.detach().numpy() 

  #def compute_mse_factual(self, x, t,c, e,w):
  def compute_mse_factual(self, x, y, e,w):

    if not self.fitted:
      raise Exception("The model has not been fitted yet. Please fit the " +
                      "model using the `fit` method on some training data " +
                      "before calling `_eval_nll`.")
      
    # processed_data = self._prepocess_training_data(x, t, c, e,w, 0, None, 0)
    # _, _,_, _,_, x_val, t_val,c_val, e_val,w_val = processed_data

    # x_val, t_val, c_val, e_val,w_val = x_val,\
    #     _reshape_tensor_with_nans(t_val),\
    #     _reshape_tensor_with_nans(c_val),\
    #     _reshape_tensor_with_nans(e_val),\
    #     _reshape_tensor_with_nans(w_val)
    # #loss = 0
    # #ll_loss = float(conditional_loss(self.torch_model,x_val, t_val, e_val,w_val, elbo=False))
    # #imb = imb_loss(self.torch_model,x_val,w_val)
    # mse = mse_loss(self.torch_model,x_val,t_val,c_val,w_val)
    # # mse = mse_total(self.torch_model,x_val,t_val,e_val,w_val)
    # #loss = ll_loss + self.torch_model.p_alpha*imb + self.torch_model.p_beta*mse

    processed_data = self._prepocess_training_data(x, y, e,w, 0, None, 0)
    _, _,_, _, x_val, y_val, e_val,w_val = processed_data

    x_val, y_val, e_val,w_val = x_val,\
        _reshape_tensor_with_nans(y_val),\
        _reshape_tensor_with_nans(e_val),\
        _reshape_tensor_with_nans(w_val)
    #loss = 0
    #ll_loss = float(conditional_loss(self.torch_model,x_val, t_val, e_val,w_val, elbo=False))
    #imb = imb_loss(self.torch_model,x_val,w_val)
    mse = mse_loss(self.torch_model,x_val,y_val,e_val,w_val)
    # mse = mse_total(self.torch_model,x_val,t_val,e_val,w_val)
    #loss = ll_loss + self.torch_model.p_alpha*imb + self.torch_model.p_beta*mse

    return mse.detach().numpy() 

  def _prepocess_test_data(self, x):
    return torch.from_numpy(x)

  # def _prepocess_training_data(self, x, t,c, e, w,vsize, val_data, random_state):

  #   idx = list(range(x.shape[0]))
  #   np.random.seed(random_state)
  #   np.random.shuffle(idx)
  #   x_train, t_train, c_train, e_train,w_train = x[idx], t[idx], c[idx] , e[idx], w[idx]

  #   x_train = torch.from_numpy(x_train).double()
  #   t_train = torch.from_numpy(t_train).double()
  #   c_train = torch.from_numpy(c_train).double()
  #   e_train = torch.from_numpy(e_train).double()
  #   w_train = torch.from_numpy(w_train).double()

  #   if val_data is None:

  #     vsize = int(vsize*x_train.shape[0])
  #     x_val, t_val, c_val, e_val,w_val = x_train[-vsize:], t_train[-vsize:], c_train[-vsize:],e_train[-vsize:], w_train[-vsize:]

  #     x_train = x_train[:-vsize]
  #     t_train = t_train[:-vsize]
  #     c_train = c_train[:-vsize]
  #     e_train = e_train[:-vsize]
  #     w_train = w_train[:-vsize]

  #   else:

  #     x_val, t_val, c_val, e_val,w_val = val_data

  #     x_val = torch.from_numpy(x_val).double()
  #     t_val = torch.from_numpy(t_val).double()
  #     c_val = torch.from_numpy(c_val).double()
  #     e_val = torch.from_numpy(e_val).double()
  #     w_val = torch.from_numpy(w_val).double()

  #   return (x_train, t_train,c_train, e_train,w_train,
  #           x_val, t_val, c_val, e_val,w_val)

  def _prepocess_training_data(self, x, y, e, w,vsize, val_data, random_state):

    idx = list(range(x.shape[0]))
    np.random.seed(random_state)
    np.random.shuffle(idx)
    x_train, y_train, e_train,w_train = x[idx], y[idx] , e[idx], w[idx]

    x_train = torch.from_numpy(x_train).double()
    y_train = torch.from_numpy(y_train).double()
    #c_train = torch.from_numpy(c_train).double()
    e_train = torch.from_numpy(e_train).double()
    w_train = torch.from_numpy(w_train).double()

    if val_data is None:

      vsize = int(vsize*x_train.shape[0])
      x_val, y_val,  e_val,w_val = x_train[-vsize:], y_train[-vsize:],e_train[-vsize:], w_train[-vsize:]

      x_train = x_train[:-vsize]
      y_train = y_train[:-vsize]
      e_train = e_train[:-vsize]
      w_train = w_train[:-vsize]

    else:

      x_val, y_val, e_val,w_val = val_data

      x_val = torch.from_numpy(x_val).double()
      y_val = torch.from_numpy(y_val).double()
      e_val = torch.from_numpy(e_val).double()
      w_val = torch.from_numpy(w_val).double()

    return (x_train, y_train, e_train,w_train,
            x_val, y_val, e_val,w_val)
    
  def predict_dist_parameters(self,x,w):
    x = self._prepocess_test_data(x)
    if self.fitted:
      return get_parameters(self.torch_model,x,w)
    else:
      raise Exception("The model has not been fitted yet. Please fit the " +
                      "model using the `fit` method on some training data " +
                      "before calling `predict_time`.")

      
  # def compute_ci(self,x,t,c,e,w):
  #   processed_data = self._prepocess_training_data(x, t,c, e,w, 0, None, 0)
  #   _, _, _,_,_, x_val, t_val,c_val, e_val,w_val = processed_data

  #   x_val, t_val, c_val,e_val,w_val = x_val,\
  #       _reshape_tensor_with_nans(t_val),\
  #       _reshape_tensor_with_nans(c_val),\
  #       _reshape_tensor_with_nans(e_val),\
  #       _reshape_tensor_with_nans(w_val)
  #   if self.fitted:
  #     treated_idx = torch.where(w_val>0)[0]                        
  #     control_idx = torch.where(w_val<1)[0]
  #     shape_co,scale_co,logits_co, shape_tr,scale_tr, logits_tr,shape_co_c,scale_co_c,logits_co_c, shape_tr_c,scale_tr_c, logits_tr_c  = get_parameters(self.torch_model,x_val,w_val)  #Predicted Factual Parameters 

  #     t_pred_f_co = auc(self.torch_model, t_val,shape_co,scale_co, logits_co )
  #     t_pred_f_tr = auc(self.torch_model,t_val,shape_tr,scale_tr, logits_tr)
  #     c_index_co = concordance_index(event_times=t_val[control_idx],predicted_scores=t_pred_f_co.detach().numpy(),event_observed=e_val[control_idx])
  #     c_index_tr = concordance_index(event_times=t_val[treated_idx],predicted_scores=t_pred_f_tr.detach().numpy(),event_observed=e_val[treated_idx])
  #     ci_index = (c_index_co + c_index_tr) * 0.5

  #     return ci_index
  #   else:
  #     raise Exception("The model has not been fitted yet. Please fit the " +
  #                     "model using the `fit` method on some training data " +
  #                     "before calling `predict_time`.")

  def compute_ci(self,x,y,e,w):
    processed_data = self._prepocess_training_data(x, y, e,w, 0, None, 0)
    _, _, _,_, x_val, y_val, e_val,w_val = processed_data

    x_val, y_val,e_val,w_val = x_val,\
        _reshape_tensor_with_nans(y_val),\
        _reshape_tensor_with_nans(e_val),\
        _reshape_tensor_with_nans(w_val)
    if self.fitted:
      treated_idx = torch.where(w_val>0)[0]                        
      control_idx = torch.where(w_val<1)[0]
      shape_co,scale_co,logits_co, shape_tr,scale_tr, logits_tr,shape_co_c,scale_co_c,logits_co_c, shape_tr_c,scale_tr_c, logits_tr_c  = get_parameters(self.torch_model,x_val,w_val)  #Predicted Factual Parameters 
      t_pred_f_co = auc(self.torch_model, y_val,shape_co,scale_co, logits_co )
      t_pred_f_tr = auc(self.torch_model, y_val, shape_tr,scale_tr,logits_tr)
      c_pred_f_co = auc(self.torch_model, y_val, shape_co_c, scale_co_c, logits_co_c)
      c_pred_f_tr = auc(self.torch_model, y_val,shape_tr_c, scale_tr_c, logits_tr_c)
      y_pred_f_co = e_val[w_val==0].cuda()*t_pred_f_co + (1-e_val[w_val==0].cuda())*c_pred_f_co
      y_pred_f_tr = e_val[w_val==1]*t_pred_f_tr + (1-e_val[w_val==1])*c_pred_f_tr
      # y_pred_f_co = auc(self.torch_model, y_val,shape_co,scale_co, logits_co )
      # y_pred_f_tr = auc(self.torch_model,y_val,shape_tr,scale_tr, logits_tr)

      
      c_index_co = concordance_index(event_times=y_val[control_idx],predicted_scores=y_pred_f_co.detach().numpy(),event_observed=e_val[control_idx])
      c_index_tr = concordance_index(event_times=y_val[treated_idx],predicted_scores=y_pred_f_tr.detach().numpy(),event_observed=e_val[treated_idx])
      ci_index = (c_index_co + c_index_tr) * 0.5

      return ci_index
    else:
      raise Exception("The model has not been fitted yet. Please fit the " +
                      "model using the `fit` method on some training data " +
                      "before calling `predict_time`.")